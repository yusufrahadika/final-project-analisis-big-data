{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ggj9ByqBTG3"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "hDw9skGnBTJv",
    "outputId": "5926fe0f-337a-4bfb-aa24-07ac448b24a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://8d0a721dbc73:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8db80c7790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FeiSq66BTPx"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9kxzRJ3BpI1"
   },
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPXPCzPoGv8x"
   },
   "source": [
    "Referensi: https://runawayhorse001.github.io/LearningApacheSpark/classification.html\n",
    "\n",
    "1. Menyiapkan spark context dan SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9pqPxgBBTUl"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"PySpark Naive Bayes Classifier\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TtjR70PHJCt"
   },
   "source": [
    "2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqOGqbNpBTXI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+---+-----+----+-----+\n",
      "|  _c0|  _c1|_c2|_c3|  _c4| _c5|  _c6|\n",
      "+-----+-----+---+---+-----+----+-----+\n",
      "|vhigh|vhigh|  2|  2|small| low|unacc|\n",
      "|vhigh|vhigh|  2|  2|small| med|unacc|\n",
      "|vhigh|vhigh|  2|  2|small|high|unacc|\n",
      "|vhigh|vhigh|  2|  2|  med| low|unacc|\n",
      "|vhigh|vhigh|  2|  2|  med| med|unacc|\n",
      "+-----+-----+---+---+-----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').load(\"dataset.txt\", header=False)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZ_0SPKVHMfy"
   },
   "source": [
    "3. Fungsi untuk mengubah fitur kategorikal menjadi numerik dan disimpan dalam bentuk *Dense Vector*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUDkW1rpBTcj"
   },
   "outputs": [],
   "source": [
    "def get_dummy(df,categoricalCols,continuousCols,labelCol):\n",
    "\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "    from pyspark.sql.functions import col\n",
    "\n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "                 for c in categoricalCols ]\n",
    "\n",
    "    # default setting: dropLast=True\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "                 for indexer in indexers ]\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                                + continuousCols, outputCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "\n",
    "    data = data.withColumn('label',col(labelCol))\n",
    "\n",
    "    return data.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmPE8A5pBTe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['_c0', '_c1', '_c2', '_c3', '_c4', '_c5'], [], '_c6')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [f\"_c{i}\" for i in range(6)]\n",
    "numeric = []\n",
    "class_output = '_c6'\n",
    "categorical, numeric, class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "oxzSyNV9EeGF",
    "outputId": "9223a6c6-bb6a-4af1-a364-c675fe585642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(15,[6,9,14],[1.0...|unacc|\n",
      "|(15,[6,9],[1.0,1.0])|unacc|\n",
      "|(15,[6,9,13],[1.0...|unacc|\n",
      "|(15,[6,9,12,14],[...|unacc|\n",
      "|(15,[6,9,12],[1.0...|unacc|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_dummy(df,categorical, numeric, class_output)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4m2FHV11Iza3"
   },
   "source": [
    "4. merubah label kategorikal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "4ppwIoQsEl6o",
    "outputId": "95c3f6d7-2625-436e-b30f-e547f8915bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|            features|label|indexedLabel|\n",
      "+--------------------+-----+------------+\n",
      "|(15,[6,9,14],[1.0...|unacc|         0.0|\n",
      "|(15,[6,9],[1.0,1.0])|unacc|         0.0|\n",
      "|(15,[6,9,13],[1.0...|unacc|         0.0|\n",
      "|(15,[6,9,12,14],[...|unacc|         0.0|\n",
      "|(15,[6,9,12],[1.0...|unacc|         0.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label',\n",
    "                             outputCol='indexedLabel').fit(data)\n",
    "labelIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nydONGsfJF0Z"
   },
   "source": [
    "5. fitur yang memiliki *unique value* lebih dari 4 akan dianggap sebagai fitur kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "iyuLbjrfEo1j",
    "outputId": "0ed87ade-b097-49ea-c971-acbabe105b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|     indexedFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(15,[6,9,14],[1.0...|unacc|(15,[6,9,14],[1.0...|\n",
      "|(15,[6,9],[1.0,1.0])|unacc|(15,[6,9],[1.0,1.0])|\n",
      "|(15,[6,9,13],[1.0...|unacc|(15,[6,9,13],[1.0...|\n",
      "|(15,[6,9,12,14],[...|unacc|(15,[6,9,12,14],[...|\n",
      "|(15,[6,9,12],[1.0...|unacc|(15,[6,9,12],[1.0...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\",\n",
    "                               outputCol=\"indexedFeatures\",\n",
    "                               maxCategories=5).fit(data)\n",
    "featureIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uu15YBu9JiIE"
   },
   "source": [
    "6. split data training:data test dengan perbandingan 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "bZBdfNdvEqxb",
    "outputId": "1a5ee4b0-bf5b-4135-ade0-c0fd918a1837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+-----+\n",
      "|features                                      |label|\n",
      "+----------------------------------------------+-----+\n",
      "|(15,[0],[1.0])                                |unacc|\n",
      "|(15,[0,3],[1.0,1.0])                          |unacc|\n",
      "|(15,[0,3,6],[1.0,1.0,1.0])                    |unacc|\n",
      "|(15,[0,3,6,9,11],[1.0,1.0,1.0,1.0,1.0])       |unacc|\n",
      "|(15,[0,3,6,9,11,13],[1.0,1.0,1.0,1.0,1.0,1.0])|unacc|\n",
      "+----------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------------------------------+-----+\n",
      "|features                                      |label|\n",
      "+----------------------------------------------+-----+\n",
      "|(15,[],[])                                    |unacc|\n",
      "|(15,[0,3,6,9],[1.0,1.0,1.0,1.0])              |unacc|\n",
      "|(15,[0,3,6,9,12,13],[1.0,1.0,1.0,1.0,1.0,1.0])|unacc|\n",
      "|(15,[0,3,6,9,12,14],[1.0,1.0,1.0,1.0,1.0,1.0])|unacc|\n",
      "|(15,[0,3,6,9,13],[1.0,1.0,1.0,1.0,1.0])       |unacc|\n",
      "+----------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "\n",
    "trainingData.show(5,False)\n",
    "testData.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaiUGo4lEvzN"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors # !!!!caution: not from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AoDmaIhMJyGf"
   },
   "source": [
    "7. fit Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzTPcpBcEv4x"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(featuresCol='indexedFeatures', labelCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5VZAJhZJ1g7"
   },
   "source": [
    "8. Arsitektur *pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wCrdbNMEv8H"
   },
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\",\n",
    "                               outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98SUxvKMEv-w"
   },
   "outputs": [],
   "source": [
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, nb,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lLyFjF6EwBg"
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5LfrQmkJ8Zk"
   },
   "source": [
    "9. Membuat prediksi menggunakan data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "Hvl9-mE_E5fr",
    "outputId": "91ae4664-4995-4f61-c462-631c08d0c389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+\n",
      "|            features|label|predictedLabel|\n",
      "+--------------------+-----+--------------+\n",
      "|          (15,[],[])|unacc|         unacc|\n",
      "|(15,[0,3,6,9],[1....|unacc|         unacc|\n",
      "|(15,[0,3,6,9,12,1...|unacc|         unacc|\n",
      "|(15,[0,3,6,9,12,1...|unacc|         unacc|\n",
      "|(15,[0,3,6,9,13],...|unacc|         unacc|\n",
      "+--------------------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wegfpbpVKCg9"
   },
   "source": [
    "10. evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZxhikIk4E5iq",
    "outputId": "3a106dc0-c461-40d0-9043-98c6ead34306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.20208\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\",\n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NaiveBayes",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
